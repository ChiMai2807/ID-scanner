{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "975a45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob, time\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd, string\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "98a0ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "corners_model = YOLO(\"detect_corners_n.pt\")\n",
    "info_model = YOLO(\"detect_info_n.pt\")\n",
    "detect_model = YOLO(\"digit_detection.pt\")\n",
    "predict_model = tf.keras.models.load_model('digit_recognition.keras', compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "17e6d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"test_1_img\"\n",
    "WARP_DIR = os.path.join(IMG_DIR, \"warped\")\n",
    "REGION_ROOT  = os.path.join(IMG_DIR, \"regions\")\n",
    "PREVIEW_DIR = os.path.join(IMG_DIR, \"preview\")\n",
    "\n",
    "os.makedirs(WARP_DIR, exist_ok=True)\n",
    "os.makedirs(REGION_ROOT, exist_ok=True)\n",
    "\n",
    "class_map_corners = {\n",
    "    2: 'top_left',\n",
    "    3: 'top_right',\n",
    "    1: 'bottom_right',\n",
    "    0: 'bottom_left'\n",
    "}\n",
    "class_map_info = {\n",
    "    2: \"name\",\n",
    "    1: \"id\",\n",
    "    0: \"dob\"\n",
    "}\n",
    "\n",
    "class_map_digits = {\n",
    "    0: 'number',\n",
    "    1: 'slash'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd43dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_miss_corner(coord):\n",
    "    # must match this exact order:\n",
    "    keys = ['top_left','top_right','bottom_left','bottom_right']\n",
    "    for i,k in enumerate(keys):\n",
    "        if k not in coord:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def calculate_missed_coord_corner(coord):\n",
    "    idx = find_miss_corner(coord)\n",
    "    # 0 → top_left missing\n",
    "    if idx == 0:\n",
    "        m = (np.array(coord['top_right']) + np.array(coord['bottom_left'])) / 2\n",
    "        coord['top_left'] = (2*m - coord['bottom_right']).tolist()\n",
    "    # 1 → top_right missing\n",
    "    elif idx == 1:\n",
    "        m = (np.array(coord['top_left']) + np.array(coord['bottom_right'])) / 2\n",
    "        coord['top_right'] = (2*m - coord['bottom_left']).tolist()\n",
    "    # 2 → bottom_left missing\n",
    "    elif idx == 2:\n",
    "        m = (np.array(coord['top_left']) + np.array(coord['bottom_right'])) / 2\n",
    "        coord['bottom_left'] = (2*m - coord['top_right']).tolist()\n",
    "    # 3 → bottom_right missing\n",
    "    elif idx == 3:\n",
    "        m = (np.array(coord['bottom_left']) + np.array(coord['top_right'])) / 2\n",
    "        coord['bottom_right'] = (2*m - coord['top_left']).tolist()\n",
    "    return coord\n",
    "\n",
    "def perspective_transform(image, src_pts):\n",
    "    dst_pts = np.float32([[0,0],[500,0],[500,300],[0,300]])\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    return cv2.warpPerspective(image, M, (500,300))\n",
    "\n",
    "def process_image_corner(img_path):\n",
    "   \n",
    "    fname = os.path.basename(img_path)\n",
    "    img_np = cv2.imread(img_path)\n",
    "\n",
    "    res     = corners_model(img_np, imgsz=640-32, verbose=False)[0]\n",
    "    boxes   = res.boxes.xyxy.cpu().numpy()\n",
    "    scores  = res.boxes.conf.cpu().numpy()\n",
    "    classes = res.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "\n",
    "    # Select best-confidence box for each corner\n",
    "    coord_dict = {}\n",
    "    for cls_id, bbox, conf in zip(classes, boxes, scores):\n",
    "        corner = class_map_corners.get(int(cls_id))\n",
    "        if not corner:\n",
    "            continue\n",
    "        prev = coord_dict.get(corner)\n",
    "        if prev is None or conf > prev[1]:\n",
    "            coord_dict[corner] = (bbox, conf)\n",
    "\n",
    "    # Calculate center points\n",
    "    centers = {\n",
    "        name: ((b[0]+b[2])/2, (b[1]+b[3])/2)\n",
    "        for name,(b,_) in coord_dict.items()\n",
    "    }\n",
    "\n",
    "    if len(centers) < 3:\n",
    "        #print(f\"[{fname}] only {len(centers)}/4 corners — saving original unchanged\")\n",
    "        cv2.imwrite(os.path.join(WARP_DIR, fname), img_np)\n",
    "        return\n",
    "    if len(centers) == 3:\n",
    "        centers = calculate_missed_coord_corner(centers)\n",
    "\n",
    "    # Warp and save\n",
    "    src = np.float32([\n",
    "        centers['top_left'],\n",
    "        centers['top_right'],\n",
    "        centers['bottom_right'],\n",
    "        centers['bottom_left']\n",
    "    ])\n",
    "    warp = perspective_transform(img_np, src)\n",
    "    out_name = os.path.splitext(fname)[0] + \".jpg\"\n",
    "    out_path = os.path.join(WARP_DIR, out_name)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    cv2.imwrite(out_path, warp)\n",
    "\n",
    "\n",
    "def process_image_infor(img_path):\n",
    "    fname = os.path.basename(img_path)\n",
    "    base, ext = os.path.splitext(fname)\n",
    "\n",
    "    # 1) Run inference\n",
    "    res     = info_model(img_path, imgsz=480, conf=0.25, verbose=False)[0]\n",
    "    boxes   = res.boxes.xyxy.cpu().numpy()\n",
    "    classes = res.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "    # 2) For each detection, crop and save\n",
    "    img = cv2.imread(img_path)\n",
    "    for box, cls_id in zip(boxes, classes):\n",
    "        field = class_map_info.get(int(cls_id))\n",
    "        if field is None:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "\n",
    "        out_name = f\"{base}.jpg\"\n",
    "        out_path = os.path.join(REGION_ROOT, field, out_name)\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        cv2.imwrite(out_path, crop)\n",
    "\n",
    "def cropped_digits(img_path, field):\n",
    "    if field == \"dob\":\n",
    "        output_dir = os.path.join(REGION_ROOT, \"digits_dob\")\n",
    "    else:\n",
    "        output_dir = os.path.join(REGION_ROOT, \"digits_id\")\n",
    "    fname = os.path.basename(img_path)\n",
    "    base, ext = os.path.splitext(fname)\n",
    "    \n",
    "    # 1) Run inference\n",
    "    res = detect_model(img_path, conf=0.85, verbose=False, save=True, save_txt=True)[0]\n",
    "    boxes   = res.boxes.xyxy.cpu().numpy()\n",
    "    classes = res.boxes.cls.cpu().numpy().astype(int)\n",
    "    img = cv2.imread(img_path)\n",
    " \n",
    "    bboxes = []\n",
    "    for cls_id, (x1, y1, x2, y2) in zip(classes, boxes):\n",
    "        if cls_id == 0:\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "            if x2 - x1 > 2 and y2 - y1 > 2:  # filter tiny boxes\n",
    "                bboxes.append((x1, y1, x2, y2))\n",
    "\n",
    "    if not bboxes:\n",
    "        #print(f\"[{fname}] No class-0 digits found.\")\n",
    "        return\n",
    "\n",
    "    # 4) Sort left to right\n",
    "    bboxes.sort(key=lambda box: box[0])\n",
    "\n",
    "    # 5) Crop and save\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i, (x1, y1, x2, y2) in enumerate(bboxes):\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "        crop = cv2.resize(crop, (28, 28))\n",
    "        out_name = f\"{base}_{i:02d}.jpg\"\n",
    "        out_path = os.path.join(output_dir, out_name)\n",
    "        cv2.imwrite(out_path, crop)\n",
    "\n",
    "    #print(f\"[{fname}] Cropped {len(bboxes)} digits to {output_dir}\")\n",
    "\n",
    "def predict_digits(img_path):\n",
    "    fname = os.path.basename(img_path)\n",
    "    base, ext = os.path.splitext(fname)\n",
    "    # 1) Read all cropped digits\n",
    "    for field in [\"id\", \"dob\"]:\n",
    "        digit_dir = os.path.join(REGION_ROOT, f\"digits_{field}\")\n",
    "        digit_files = sorted(glob.glob(os.path.join(digit_dir, f\"{base}_*.jpg\")))\n",
    "\n",
    "        if not digit_files:\n",
    "            #print(f\"[{fname}] No cropped digits found.\")\n",
    "            return\n",
    "        batch = []\n",
    "        for file in digit_files:\n",
    "            img = cv2.imread(file, cv2.IMREAD_COLOR)         \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        \n",
    "            img = cv2.resize(img, (28, 28))\n",
    "            img = img.astype(\"float32\") \n",
    "            batch.append(img)\n",
    "\n",
    "        batch_input = np.stack(batch, axis=0)\n",
    "\n",
    "        preds = predict_model.predict(batch_input, verbose=0)\n",
    "        digits = np.argmax(preds, axis=1)\n",
    "\n",
    "        digit_str = ''.join(map(str, digits))\n",
    "        if field == \"dob\":\n",
    "            digit_str = f\"{digit_str[:2]}/{digit_str[2:4]}/{digit_str[4:8]}{digit_str[8:]}\" if len(digit_str) >= 8 else digit_str\n",
    "        print(f\"[{fname}] Predicted {field} digits: {digit_str}\")\n",
    "    return digit_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "3eeb0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    for img_path in sorted(glob.glob(os.path.join(IMG_DIR, \"*.*\"))):\n",
    "        fname = os.path.basename(img_path)\n",
    "\n",
    "        #detect 4 corners and save warped images\n",
    "        t1 = time.perf_counter()\n",
    "        process_image_corner(img_path)\n",
    "        print(f\"✅ Corners & warp done in {time.perf_counter() - t1:.2f} sec\")\n",
    "\n",
    "        #detect info and save regions\n",
    "        t2 = time.perf_counter()\n",
    "        warp_image_path = os.path.join(WARP_DIR, fname )\n",
    "        process_image_infor(warp_image_path)\n",
    "        print(f\"✅ Info detection done in {time.perf_counter() - t2:.2f} sec\")\n",
    "\n",
    "        #detect digits and save regions\n",
    "        t3 = time.perf_counter()\n",
    "        cropped_digits(os.path.join(REGION_ROOT, \"dob\", fname), \"dob\")\n",
    "        cropped_digits(os.path.join(REGION_ROOT, \"id\", fname), \"id\")\n",
    "        \n",
    "        print(f\"✅ Cropped digits done in {time.perf_counter() - t3:.2f} sec\")\n",
    "        #predict digits\n",
    "        t4 = time.perf_counter()\n",
    "        predict_digits(img_path)\n",
    "\n",
    "        print(f\"✅ Digit predictions done in {time.perf_counter() - t4:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "02649b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Corners & warp done in 0.06 sec\n",
      "✅ Info detection done in 0.03 sec\n",
      "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n",
      "1 label saved to runs/detect/predict3/labels\n",
      "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n",
      "1 label saved to runs/detect/predict3/labels\n",
      "✅ Cropped digits done in 0.05 sec\n",
      "[29.jpg] Predicted id digits: 096202006939\n",
      "[29.jpg] Predicted dob digits: 01/01/2002\n",
      "✅ Digit predictions done in 0.08 sec\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
