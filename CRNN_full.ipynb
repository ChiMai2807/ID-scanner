{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "36e78e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob, time\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd, string\n",
    "from ultralytics import YOLO\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "71bb35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "corners_model = YOLO(\"detect_corners_n.pt\")\n",
    "info_model = YOLO(\"detect_info_n.pt\")\n",
    "predict_id_model = tf.keras.models.load_model('model_id_1.keras', compile=False, safe_mode=False)\n",
    "predict_dob_model = tf.keras.models.load_model('dob_model_1_.keras', compile=False, safe_mode=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e6b701b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"test_1_img\"\n",
    "WARP_DIR = os.path.join(IMG_DIR, \"warped\")\n",
    "REGION_ROOT  = os.path.join(IMG_DIR, \"regions\")\n",
    "PREVIEW_DIR = os.path.join(IMG_DIR, \"preview\")\n",
    "\n",
    "os.makedirs(WARP_DIR, exist_ok=True)\n",
    "os.makedirs(REGION_ROOT, exist_ok=True)\n",
    "\n",
    "class_map_corners = {\n",
    "    2: 'top_left',\n",
    "    3: 'top_right',\n",
    "    1: 'bottom_right',\n",
    "    0: 'bottom_left'\n",
    "}\n",
    "class_map_info = {\n",
    "    2: \"name\",\n",
    "    1: \"id\",\n",
    "    0: \"dob\"\n",
    "}\n",
    "# Vocabulary & encoder\n",
    "char_list   = string.ascii_letters + string.digits\n",
    "blank_index = len(char_list)\n",
    "\n",
    "BLANK = len(char_list)\n",
    "index_to_char = {i: c for i, c in enumerate(char_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c0b4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_miss_corner(coord):\n",
    "    # must match this exact order:\n",
    "    keys = ['top_left','top_right','bottom_left','bottom_right']\n",
    "    for i,k in enumerate(keys):\n",
    "        if k not in coord:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def calculate_missed_coord_corner(coord):\n",
    "    idx = find_miss_corner(coord)\n",
    "    # 0 → top_left missing\n",
    "    if idx == 0:\n",
    "        m = (np.array(coord['top_right']) + np.array(coord['bottom_left'])) / 2\n",
    "        coord['top_left'] = (2*m - coord['bottom_right']).tolist()\n",
    "    # 1 → top_right missing\n",
    "    elif idx == 1:\n",
    "        m = (np.array(coord['top_left']) + np.array(coord['bottom_right'])) / 2\n",
    "        coord['top_right'] = (2*m - coord['bottom_left']).tolist()\n",
    "    # 2 → bottom_left missing\n",
    "    elif idx == 2:\n",
    "        m = (np.array(coord['top_left']) + np.array(coord['bottom_right'])) / 2\n",
    "        coord['bottom_left'] = (2*m - coord['top_right']).tolist()\n",
    "    # 3 → bottom_right missing\n",
    "    elif idx == 3:\n",
    "        m = (np.array(coord['bottom_left']) + np.array(coord['top_right'])) / 2\n",
    "        coord['bottom_right'] = (2*m - coord['top_left']).tolist()\n",
    "    return coord\n",
    "\n",
    "def perspective_transform(image, src_pts):\n",
    "    dst_pts = np.float32([[0,0],[500,0],[500,300],[0,300]])\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    return cv2.warpPerspective(image, M, (500,300))\n",
    "\n",
    "def process_image_corner(img_path):\n",
    "   \n",
    "    fname = os.path.basename(img_path)\n",
    "    img_np = cv2.imread(img_path)\n",
    "\n",
    "    res     = corners_model(img_np, imgsz=640-32, verbose=False)[0]\n",
    "    boxes   = res.boxes.xyxy.cpu().numpy()\n",
    "    scores  = res.boxes.conf.cpu().numpy()\n",
    "    classes = res.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "\n",
    "    # Select best-confidence box for each corner\n",
    "    coord_dict = {}\n",
    "    for cls_id, bbox, conf in zip(classes, boxes, scores):\n",
    "        corner = class_map_corners.get(int(cls_id))\n",
    "        if not corner:\n",
    "            continue\n",
    "        prev = coord_dict.get(corner)\n",
    "        if prev is None or conf > prev[1]:\n",
    "            coord_dict[corner] = (bbox, conf)\n",
    "\n",
    "    # Calculate center points\n",
    "    centers = {\n",
    "        name: ((b[0]+b[2])/2, (b[1]+b[3])/2)\n",
    "        for name,(b,_) in coord_dict.items()\n",
    "    }\n",
    "\n",
    "    if len(centers) < 3:\n",
    "        print(f\"[{fname}] ⚠️ only {len(centers)}/4 corners — saving original unchanged\")\n",
    "        cv2.imwrite(os.path.join(WARP_DIR, fname), img_np)\n",
    "        return\n",
    "    if len(centers) == 3:\n",
    "        centers = calculate_missed_coord_corner(centers)\n",
    "\n",
    "    # Warp and save\n",
    "    src = np.float32([\n",
    "        centers['top_left'],\n",
    "        centers['top_right'],\n",
    "        centers['bottom_right'],\n",
    "        centers['bottom_left']\n",
    "    ])\n",
    "    warp = perspective_transform(img_np, src)\n",
    "    out_name = os.path.splitext(fname)[0] + \".jpg\"\n",
    "    out_path = os.path.join(WARP_DIR, out_name)\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    cv2.imwrite(out_path, warp)\n",
    "\n",
    "\n",
    "def process_image_infor(img_path):\n",
    "    fname = os.path.basename(img_path)\n",
    "    base, ext = os.path.splitext(fname)\n",
    "\n",
    "    # 1) Run inference\n",
    "    res     = info_model(img_path, imgsz=480, conf=0.25, verbose=False)[0]\n",
    "    boxes   = res.boxes.xyxy.cpu().numpy()\n",
    "    classes = res.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "    # 2) For each detection, crop and save\n",
    "    img = cv2.imread(img_path)\n",
    "    for box, cls_id in zip(boxes, classes):\n",
    "        field = class_map_info.get(int(cls_id))\n",
    "        if field is None:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "\n",
    "        out_name = f\"{base}.jpg\"\n",
    "        out_path = os.path.join(REGION_ROOT, field, out_name)\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        cv2.imwrite(out_path, crop)\n",
    "\n",
    "\n",
    "def preprocess(img, target_h=15, max_w=128):\n",
    "    \"\"\"\n",
    "    Resize grayscale img so its height == target_h, then\n",
    "    scale width, and pad or truncate to max_w. Returns\n",
    "    a float32 array shape (target_h, max_w, 1) in [0,1].\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # 1) Scale so height == target_h\n",
    "    scale = target_h / float(h)\n",
    "    new_w = int(w * scale)\n",
    "    img = cv2.resize(img, (new_w, target_h))\n",
    "\n",
    "    # 2) Pad or truncate width to max_w\n",
    "    if new_w < max_w:\n",
    "        # pad right side with white (255)\n",
    "        pad = np.ones((target_h, max_w - new_w), dtype=img.dtype) * 255\n",
    "        img = np.concatenate([img, pad], axis=1)\n",
    "    else:\n",
    "        # truncate any extras on the right\n",
    "        img = img[:, :max_w]\n",
    "\n",
    "    # 3) Normalize to [0,1] and add channel dim\n",
    "    img = img.astype('float32') / 255.0\n",
    "    return img[..., np.newaxis]  # shape (32, max_w, 1)\n",
    "char_to_idx = {c:i for i,c in enumerate(char_list)}\n",
    "def encode_to_labels(txt):\n",
    "    return [char_to_idx[c] for c in txt if c in char_to_idx]\n",
    "\n",
    "def predict_texts(model, paths, target_h):\n",
    "    imgs, bases = [], []\n",
    "    for p in paths:\n",
    "        raw = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "        img = preprocess(raw, target_h=target_h, max_w=128)\n",
    "        imgs.append(img)\n",
    "        bases.append(os.path.splitext(os.path.basename(p))[0])\n",
    "    imgs = np.stack(imgs, axis=0)\n",
    "\n",
    "    y_pred = model.predict(imgs)\n",
    "    input_len = np.full((y_pred.shape[0],), y_pred.shape[1], dtype='int32')\n",
    "    decoded, _ = K.ctc_decode(y_pred, input_length=input_len, greedy=True)\n",
    "    decoded = decoded[0].numpy()\n",
    "\n",
    "    texts = []\n",
    "    for seq in decoded:\n",
    "        s = ''.join(index_to_char[i] for i in seq if 0 <= i < len(char_list))\n",
    "        texts.append(s)\n",
    "    return bases, texts\n",
    "\n",
    "def format_dob(s):\n",
    "    return f\"{s[:2]}/{s[2:4]}/{s[4:8]}{s[8:]}\" if len(s) >= 8 else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "48714a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "\n",
    "\n",
    "    #detect 4 corners and save warped images\n",
    "    t1 = time.perf_counter()\n",
    "    img_paths = sorted(glob.glob(os.path.join(IMG_DIR, \"*.*\")))\n",
    "    with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        executor.map(process_image_corner, img_paths )\n",
    "    print(f\"✅ Corners & warp done in {time.perf_counter() - t1:.2f} sec\")\n",
    "\n",
    "    #detect info and save regions\n",
    "    t2 = time.perf_counter()\n",
    "    image_paths = sorted(glob.glob(os.path.join(WARP_DIR, \"*.*\")))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        executor.map(process_image_infor, image_paths)\n",
    "    print(f\"✅ Info detection done in {time.perf_counter() - t2:.2f} sec\")\n",
    "\n",
    "    #Predict ID and DOB and save to CSV\n",
    "    t3 = time.perf_counter()\n",
    "    id_paths = sorted(glob.glob(os.path.join(REGION_ROOT, \"id\",\"*.jpg\")))\n",
    "    id_bases, id_preds = predict_texts(predict_id_model, id_paths, target_h=15)\n",
    "\n",
    "    dob_paths = sorted(glob.glob(os.path.join(REGION_ROOT, \"dob\",\"*.jpg\")))\n",
    "    _, dob_preds = predict_texts(predict_dob_model, dob_paths, target_h=20)\n",
    "\n",
    "    dob_preds = [format_dob(s) for s in dob_preds]\n",
    "    df = pd.DataFrame({'image_file': id_bases, 'id': id_preds, 'dob': dob_preds})\n",
    "    df.to_csv('predictions.csv', index=False)\n",
    "    print(f\"✅ Predictions done and saved in {time.perf_counter() - t3:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0c0edb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Corners & warp done in 0.06 sec\n",
      "✅ Info detection done in 0.03 sec\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "✅ Predictions done and saved in 0.10 sec\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
