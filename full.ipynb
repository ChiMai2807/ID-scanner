{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935d3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os, glob, cv2, numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd, string\n",
    "import os, glob, cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31498fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Helper functions ─────────────────────────────────────────────────────────\n",
    "\n",
    "def find_miss_corner(coord):\n",
    "    # must match this exact order:\n",
    "    keys = ['top_left','top_right','bottom_left','bottom_right']\n",
    "    for i,k in enumerate(keys):\n",
    "        if k not in coord:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def calculate_missed_coord_corner(coord):\n",
    "    idx = find_miss_corner(coord)\n",
    "    # 0 → top_left missing\n",
    "    if idx == 0:\n",
    "        m = (np.array(coord['top_right']) + np.array(coord['bottom_left'])) / 2\n",
    "        coord['top_left'] = (2*m - coord['bottom_right']).tolist()\n",
    "    # 1 → top_right missing\n",
    "    elif idx == 1:\n",
    "        m = (np.array(coord['top_left']) + np.array(coord['bottom_right'])) / 2\n",
    "        coord['top_right'] = (2*m - coord['bottom_left']).tolist()\n",
    "    # 2 → bottom_left missing\n",
    "    elif idx == 2:\n",
    "        m = (np.array(coord['top_left']) + np.array(coord['bottom_right'])) / 2\n",
    "        coord['bottom_left'] = (2*m - coord['top_right']).tolist()\n",
    "    # 3 → bottom_right missing\n",
    "    elif idx == 3:\n",
    "        m = (np.array(coord['bottom_left']) + np.array(coord['top_right'])) / 2\n",
    "        coord['bottom_right'] = (2*m - coord['top_left']).tolist()\n",
    "    return coord\n",
    "\n",
    "def perspective_transform(image, src_pts):\n",
    "    dst_pts = np.float32([[0,0],[500,0],[500,300],[0,300]])\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    return cv2.warpPerspective(image, M, (500,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57202797",
   "metadata": {},
   "outputs": [],
   "source": [
    "corners_model = YOLO(\"detect_corners_n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce0ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[img1278.jpg] ⚠️ only 2/4 corners — saving original unchanged\n",
      "[img1280.jpg] ⚠️ only 2/4 corners — saving original unchanged\n",
      "[img1283.jpg] ⚠️ only 2/4 corners — saving original unchanged\n",
      "[img1287.jpg] ⚠️ only 2/4 corners — saving original unchanged\n",
      "[img1294.jpg] ⚠️ only 2/4 corners — saving original unchanged\n",
      "[img1297.jpg] ⚠️ only 0/4 corners — saving original unchanged\n",
      "[img1299.jpg] ⚠️ only 2/4 corners — saving original unchanged\n",
      "[img1333.jpg] ⚠️ only 2/4 corners — saving original unchanged\n",
      "[img1375.jpg] ⚠️ only 0/4 corners — saving original unchanged\n",
      "[img1621.jpg] ⚠️ only 2/4 corners — saving original unchanged\n",
      "[img932.jpg] ⚠️ only 2/4 corners — saving original unchanged\n",
      "✅ All images processed.\n"
     ]
    }
   ],
   "source": [
    "import glob, os, cv2\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "IMG_DIR  = \"testset1\"\n",
    "PREV_DIR = os.path.join(IMG_DIR, \"4_corners\")\n",
    "WARP_DIR = os.path.join(IMG_DIR, \"warped\")\n",
    "\n",
    "os.makedirs(PREV_DIR, exist_ok=True)\n",
    "os.makedirs(WARP_DIR, exist_ok=True)\n",
    "\n",
    "class_map = {\n",
    "    2: 'top_left',\n",
    "    3: 'top_right',\n",
    "    1: 'bottom_right',\n",
    "    0: 'bottom_left'\n",
    "}\n",
    "\n",
    "def process_image(img_path):\n",
    "    \n",
    "    fname = os.path.basename(img_path)\n",
    "    img_np = cv2.imread(img_path)\n",
    "\n",
    "    res     = corners_model(img_np, imgsz=640-32, verbose=False)[0]\n",
    "    boxes   = res.boxes.xyxy.cpu().numpy()\n",
    "    scores  = res.boxes.conf.cpu().numpy()\n",
    "    classes = res.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "    # Save annotated preview\n",
    "    annotated = res.plot()\n",
    "    cv2.imwrite(os.path.join(PREV_DIR, fname), annotated)\n",
    "\n",
    "    # Select best-confidence box for each corner\n",
    "    coord_dict = {}\n",
    "    for cls_id, bbox, conf in zip(classes, boxes, scores):\n",
    "        corner = class_map.get(int(cls_id))\n",
    "        if not corner:\n",
    "            continue\n",
    "        prev = coord_dict.get(corner)\n",
    "        if prev is None or conf > prev[1]:\n",
    "            coord_dict[corner] = (bbox, conf)\n",
    "\n",
    "    # Calculate center points\n",
    "    centers = {\n",
    "        name: ((b[0]+b[2])/2, (b[1]+b[3])/2)\n",
    "        for name,(b,_) in coord_dict.items()\n",
    "    }\n",
    "\n",
    "    if len(centers) < 3:\n",
    "        print(f\"[{fname}] ⚠️ only {len(centers)}/4 corners — saving original unchanged\")\n",
    "        count+=1\n",
    "        cv2.imwrite(os.path.join(WARP_DIR, fname), img_np)\n",
    "        return\n",
    "    if len(centers) == 3:\n",
    "        centers = calculate_missed_coord_corner(centers)\n",
    "\n",
    "    # Warp and save\n",
    "    src = np.float32([\n",
    "        centers['top_left'],\n",
    "        centers['top_right'],\n",
    "        centers['bottom_right'],\n",
    "        centers['bottom_left']\n",
    "    ])\n",
    "    warp = perspective_transform(img_np, src)\n",
    "    out_name = os.path.splitext(fname)[0] + \".jpg\"\n",
    "    cv2.imwrite(os.path.join(WARP_DIR, out_name), warp)\n",
    "\n",
    "# Run in parallel (4 threads)\n",
    "img_paths = sorted(glob.glob(os.path.join(IMG_DIR, \"*.*\")))\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(process_image, img_paths)\n",
    "\n",
    "print(\"✅ All images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a0a10063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load your info-detection model\n",
    "info_model = YOLO(\"detect_info_n.pt\")\n",
    "\n",
    "# 2) Folders\n",
    "WARP_DIR     = \"testset1/warped\"\n",
    "REGION_ROOT  = \"testset1/regions\"\n",
    "os.makedirs(REGION_ROOT, exist_ok=True)\n",
    "\n",
    "# 3) Map model class IDs → field names\n",
    "#    adjust these IDs to whatever your model uses\n",
    "class_map_info = {\n",
    "    2: \"name\",\n",
    "    1: \"id\",\n",
    "    0: \"dob\"\n",
    "}\n",
    "\n",
    "# Create one subfolder per field\n",
    "for field in class_map_info.values():\n",
    "    os.makedirs(os.path.join(REGION_ROOT, field), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "70895699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done! Cropped field images in: testset1/regions\n"
     ]
    }
   ],
   "source": [
    "def process_image(img_path):\n",
    "    fname = os.path.basename(img_path)\n",
    "    base, ext = os.path.splitext(fname)\n",
    "\n",
    "    # 1) Run inference\n",
    "    res     = info_model(img_path, imgsz=480, conf=0.25, verbose=False)[0]\n",
    "    boxes   = res.boxes.xyxy.cpu().numpy()\n",
    "    classes = res.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "    # 2) For each detection, crop and save\n",
    "    img = cv2.imread(img_path)\n",
    "    for box, cls_id in zip(boxes, classes):\n",
    "        field = class_map_info.get(int(cls_id))\n",
    "        if field is None:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "\n",
    "        out_name = f\"{base}.jpg\"\n",
    "        out_path = os.path.join(REGION_ROOT, field, out_name)\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        cv2.imwrite(out_path, crop)\n",
    "\n",
    "# Use thread pool to process multiple images concurrently\n",
    "image_paths = sorted(glob.glob(os.path.join(WARP_DIR, \"*.*\")))\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    executor.map(process_image, image_paths)\n",
    "\n",
    "print(\"\\n✅ Done! Cropped field images in:\", REGION_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1bf11a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(img, target_h=15, max_w=128):\n",
    "    \"\"\"\n",
    "    Resize grayscale img so its height == target_h, then\n",
    "    scale width, and pad or truncate to max_w. Returns\n",
    "    a float32 array shape (target_h, max_w, 1) in [0,1].\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # 1) Scale so height == target_h\n",
    "    scale = target_h / float(h)\n",
    "    new_w = int(w * scale)\n",
    "    img = cv2.resize(img, (new_w, target_h))\n",
    "\n",
    "    # 2) Pad or truncate width to max_w\n",
    "    if new_w < max_w:\n",
    "        # pad right side with white (255)\n",
    "        pad = np.ones((target_h, max_w - new_w), dtype=img.dtype) * 255\n",
    "        img = np.concatenate([img, pad], axis=1)\n",
    "    else:\n",
    "        # truncate any extras on the right\n",
    "        img = img[:, :max_w]\n",
    "\n",
    "    # 3) Normalize to [0,1] and add channel dim\n",
    "    img = img.astype('float32') / 255.0\n",
    "    return img[..., np.newaxis]  # shape (32, max_w, 1)\n",
    "\n",
    "# Vocabulary & encoder\n",
    "char_list   = string.ascii_letters + string.digits\n",
    "blank_index = len(char_list)\n",
    "char_to_idx = {c:i for i,c in enumerate(char_list)}\n",
    "\n",
    "def encode_to_labels(txt):\n",
    "    return [char_to_idx[c] for c in txt if c in char_to_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "517d0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b1603ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Now load via standalone Keras\n",
    "import keras\n",
    "model = tf.keras.models.load_model('model_id_1.keras', compile=False, safe_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7e0cce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 51ms/step\n",
      "['052201008654', '094204000594', '049300009355', '066203002942', '042203008521', '048203006839', '034203011524', '082203007927', '049300009355', '058304002184', '033206007176', '086203000075', '058304000867', '082203000690', '056201009956', '075203019088', '075178009364', '095202002441', '033206007176', '024202006474', '056205011350', '094204000594', '08620300075', '049303000052', '066203002942', '080203009952', '042205007349', '060203003122', '080203009952', '022190002155', '024202006474', '067305005161', '022206004066', '075303000545', '067305005161', '058205000955', '054187010523', '075303000545', '079206032383', '079203034457', '079308045547', '079203021222', '022206004066', '086203009857', '042168010024', '049203011774', '082203019158', '089203011696', '042203008521', '040203008081', '048304006054', '033089011981', '089203011672', '079089000970', '079203030140', '067203000435', '082203000690', '079203021222', '075087004519', '075203019088', '042168010024', '075203019088', '026205000366', '064203011357', '048203008173', '048203003549', '048203004023', '064203009448', '048203008044', '084203003400', '072203001090', '060202006751', '026205000366', '086203000075', '086203000075', '001304003179', '068189005662', '019078016532', '066203001463', '075203019265', '084203000281', '040090045508', '056202005860', '060202008702', '084203003457', '089091020007', '034203011524', '001304003179', '025205006066', '048203006323', '083203000265', '075204022419', '048203007477', '048203002981', '048203006839', '060203012223', '075204010026', '049303008415', '048203005109', '025205006066', '074203009205', '034093009347', '014080009801', '089193015052', '096197012556', '030076013239', '011094007911', '015085010856', '010098005498', '015094010369', '048098006238', '079089001918', '072093005614', '002202010447', '051186013101', '004181004072', '079203042786', '079192019848', '082203007927', '001160013808', '001082001120', '001039008708', '001068019072', '001053019511', '001080043263', '001140010337', '001070040815', '001049007352', '001085038291', '001055000660', '001085012312', '001147005465', '001074037986', '001172021036', '001056006123', '001159012028', '027134000017', '001161000859', '001065005343', '001056009165', '001181039694', '001154012069', '001076001767', '030155008651', '001064010140', '001182000588', '001089033601', '024167000535', '001142001457', '002086000477', '083303007509', '002086000477', '020092005281', '001197015896', '030202006686', '058304000867', '058304000867', '074097008118', '080305006099', '080305006099', '079197027398', '091194007697', '038203008269', '049085014514', '022203001529', '049088000226', '017300006607', '008202004278', '075091011605', '082203000690', '074097008118', '022206010502', '027085009308', '001203007868', '091203002648', '080196001894', '034081016195', '034081016195', '001079052151', '089193016990', '040079002549', '033300005868', '079098024355', '022206010502', '058190001014', '001066001936', '019302009164', '077197000346', '079094030899', '010202003279', '042201013037', '019099000623', '024095008284', '060203000644', '060203000644', '064086013071', '024203000184', '067096002522', '060191016770', '060191016770', '044096005077', '035205001299', '054207000321', '017200000750', '049205001642', '040187020594', '052201008654', '064086013071', '052200008869', '001301022194', '034192004388', '040095004876', '066303002629', '079187035038', '001099028195', '027191004716', '033095000010', '052200008869', '060203003122', '077199003304', '001099003427', '089200015551', '087097017737', '075301012298', '079200012258', '019193001240', '025205013294', '079094003237', '027093002309', '079095026432', '066204006537', '092090006087', '001090011658', '044205008186', '060201006347', '001206005601', '025205013294', '079081014778', '026304002883', '036096015859', '066089005586', '048305000078', '040203022796', '027092013454', '036196012656', '075204010026', '064203009448', '060203003122', '084203002125', '060203000644']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 3) You can now do inference as usual\n",
    "#    e.g. y_pred = model.predict(batch_of_images)\n",
    "\n",
    "\n",
    "# 3) Prepare your mappings\n",
    "BLANK = len(char_list)\n",
    "index_to_char = {i: c for i, c in enumerate(char_list)}\n",
    "\n",
    "# 4) Load + preprocess all validation images\n",
    "valid_paths = sorted(glob.glob('testset1/regions/id/*.jpg'))\n",
    "imgs, bases = [], []\n",
    "for p in valid_paths:\n",
    "    raw = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "    img = preprocess(raw, target_h=15, max_w=128)   # → (15, w, 1)\n",
    "    imgs.append(img)\n",
    "    bases.append(os.path.splitext(os.path.basename(p))[0])\n",
    "imgs = np.stack(imgs, axis=0)    # → (N_valid, 15, w, 1)\n",
    "\n",
    "# 5) Predict the per-timestep softmax\n",
    "y_pred = model.predict(imgs)  \n",
    "#    shape = (N_valid, time_steps, num_classes)\n",
    "\n",
    "# 6) Build input lengths for CTC\n",
    "input_len = np.ones((y_pred.shape[0],), dtype='int32') * y_pred.shape[1]\n",
    "\n",
    "# 7) Greedy CTC decode\n",
    "decoded, _ = K.ctc_decode(    \n",
    "    y_pred,\n",
    "    input_length=input_len,\n",
    "    greedy=True\n",
    ")\n",
    "decoded = decoded[0].numpy()     # → (N_valid, ≤time_steps)\n",
    "\n",
    "# 8) Convert integer sequences back to strings\n",
    "pred_texts = []\n",
    "\n",
    "for seq in decoded:\n",
    "    chars = [index_to_char[i] for i in seq if 0 <= i < len(char_list)]\n",
    "    pred_texts.append(''.join(chars))\n",
    "\n",
    "# for path, base, pred in zip(valid_paths, bases, pred_texts):\n",
    "#     img = cv2.imread(path)\n",
    "#     rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.imshow(rgb)              # display as grayscale\n",
    "#     plt.title(f\"Predicted: {pred}\")\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "print(pred_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2075c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# 1.1) Enable XLA\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# 1.2) Wrap your model call + CTC‐decode in a tf.function\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,20,128,1], tf.float32)])\n",
    "def infer_and_decode_dob(batch_images):\n",
    "    # batch_images: [B,15,128,1]\n",
    "    y = model(batch_images, training=False)  # (B, T, C)\n",
    "    # build a length vector [T,T,...]\n",
    "    lengths = tf.fill([tf.shape(y)[0]], tf.shape(y)[1])\n",
    "    decoded, _ = K.ctc_decode(y, input_length=lengths, greedy=True)\n",
    "    return decoded[0]   # shape: (B, ≤T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "dff0646a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['24/03/2001', '05/09/2004', '14/05/2000', '09/12/2003', '10/07/2003', '13/04/2003', '27/02/2003', '23/08/2003', '14/05/2000', '31/10/2004', '19/06/2006', '21/11/2003', '28/10/2004', '26/05/2003', '20/06/2001', '17/11/2003', '20/10/1978', '17/11/2002', '19/06/2006', '07/03/2002', '25/11/2005', '05/09/2004', '21/11/2003', '17/04/2003', '09/12/2003', '27/10/2003', '29/07/2005', '28/05/2003', '27/10/2003', '23/05/1990', '07/03/2002', '04/03/2005', '03/12/2006', '19/03/2003', '04/03/2005', '20/70/62005', '10/06/1987', '19/03/2003', '26/08/2006', '22/02/2003', '08/05/2008', '03/10/2003', '03/12/2006', '9122003', '09/09/1968', '27/10/2003', '22/11/2003', '25/11/2003', '10/07/2003', '05/02/2003', '20/11/2004', '12/07/1989', '02/01/02003', '01/10/1989', '14/04/2003', '30/04/2003', '26/05/2003', '03/10/2003', '03/11/1987', '17/11/2003', '09/09/1968', '17/11/2003', '23/08/2005', '15/11/2003', '21/10/2003', '10/07/2003', '14/04/2003', '04/12/2003', '14/05/2003', '0712003', '02/01/2003', '22/03/2002', '23/08/2005', '21/11/2003', '21/11/2003', '20/07/2004', '15/09/1989', '29/04/1978', '29/05/2003', '10/10/2003', '10/07/2003', '12/12/1990', '2012002', '04/03/2002', '09/03/2003', '08/11/1991', '27/02/2003', '20/07/2004', '12/01/2005', '27/04/2003', '09/10/2003', '01/11/2004', '24/11/2003', '06/10/2003', '13/04/21999', '24/07/2003', '21/01/2004', '11/12/2003', '16/08/2003', '12/01/2005', '07/11/2003', '18/04/1993', '03/05/1980', '13/08/1993', '18/01/1997', '05/06/1976', '28/11/1994', '22/12/1985', '25/05/1998', '12/09/1994', '22/08/1998', '29/10/1989', '30/07/1993', '05/12/2002', '10/06/1986', '08/08/1981', '09/01/2003', '06/06/1992', '23/08/2003', '08/04/1960', '09/10/1982', '25/11/1939', '01/12/1968', '18/09/1953', '26/12/1980', '16/07/1940', '19/10/1970', '20/07/1949', '25/04/1985', '07/07/1955', '31/12/1985', '12/08/1947', '9011974', '20/07/1972', '12/07/1956', '09/09/1959', '23/11/1934', '08/06/1961', '04/01/1965', '11/03/1956', '31/05/1981', '20/08/1954', '07/01/1976', '11/09/1955', '27/07/1964', '28/06/1982', '28/02/1989', '11/08/1967', '10/05/1942', '19/12/1986', '10/01/2003', '19/12/1986', '11/04/1992', '23/12/1997', '17/05/2002', '28/10/2004', '28/10/2004', '16/01/1997', '24/09/2005', '24/09/2005', '01/01/1997', '03/11/1994', '05/06/2003', '16/10/1985', '01/08/2003', '12/05/1988', '05/03/2000', '15/11/2002', '11/11/1991', '26/05/2003', '16/01/1997', '09/07/2006', '28/08/1985', '17/10/2003', '31/07/2003', '23/11/1996', '08/10/1981', '08/10/1981', '24/08/1979', '30/10/1993', '24/02/1979', '05/03/2000', '10/02/1998', '09/07/2006', '16/08/1990', '20/07/1966', '18/02/2002', '31/01/1997', '10/01/1994', '25/08/2002', '20/02/2001', '25/04/1999', '26/06/1995', '11/04/2003', '11/04/2003', '25/07/1986', '11/11/2003', '20/08/1996', '17/09/1991', '17/09/1991', '17/08/1996', '11/12/2005', '30/04/2007', '20/07/2000', '10/05/2005', '15/05/1987', '24/03/2001', '25/07/1986', '16/10/2000', '29/11/2001', '30/12/1992', '15/05/1995', '25/10/2003', '24/07/1987', '03/11/1999', '06/11/1991', '02/10/1995', '16/10/2000', '28/05/2003', '13/09/1999', '28/12/1999', '12/03/2000', '05/10/1997', '27/09/2001', '14/03/2000', '17/04/1993', '23/11/2005', '01/06/1994', '03/03/1993', '26/03/1995', '18/07/2004', '03/02/1990', '23/06/1990', '07/12/2005', '21/09/2001', '29/03/2006', '23/11/2005', '05/07/1981', '29/02/2004', '06/04/1996', '20/04/1989', '04/11/2005', '20/08/2003', '26/03/1992', '12/12/1996', '21/01/2004', '04/12/2003', '28/05/2003', '15/03/2003', '11/04/2003']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2) Now load via standalone Keras\n",
    "import keras\n",
    "model = tf.keras.models.load_model('dob_model_1_.keras', compile=False, safe_mode=False)\n",
    "\n",
    "# 3) You can now do inference as usual\n",
    "#    e.g. y_pred = model.predict(batch_of_images)\n",
    "\n",
    "\n",
    "# 3) Prepare your mappings\n",
    "BLANK = len(char_list)\n",
    "index_to_char = {i: c for i, c in enumerate(char_list)}\n",
    "\n",
    "# 4) Load + preprocess all validation images\n",
    "valid_paths = sorted(glob.glob('testset1/regions/dob/*.jpg'))\n",
    "imgs, bases = [], []\n",
    "for p in valid_paths:\n",
    "    raw = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
    "    img = preprocess(raw, target_h=20, max_w=128)   # → (15, w, 1)\n",
    "    imgs.append(img)\n",
    "    bases.append(os.path.splitext(os.path.basename(p))[0])\n",
    "imgs = np.stack(imgs, axis=0)    # → (N_valid, 15, w, 1)\n",
    "\n",
    "# 5) Predict the per-timestep softmax\n",
    "batch_size = 13\n",
    "all_seqs = []\n",
    "for i in range(0, len(imgs), batch_size):\n",
    "    batch = imgs[i:i+batch_size].astype('float32')\n",
    "    seqs = infer_and_decode_dob(tf.constant(batch)).numpy()  # one graph launch\n",
    "    all_seqs.extend(seqs)  \n",
    "#    shape = (N_valid, time_steps, num_classes)\n",
    "\n",
    "    # → (N_valid, ≤time_steps)\n",
    "\n",
    "# 8) Convert integer sequences back to strings\n",
    "pred_texts = []\n",
    "\n",
    "for seq in all_seqs:\n",
    "    # turn indices → raw digit string\n",
    "    s = ''.join(index_to_char[i] for i in seq if 0 <= i < len(char_list))\n",
    "\n",
    "    # if we have at least 8 digits, format the DOB portion\n",
    "    if len(s) >= 8:\n",
    "        dd, mm, yyyy = s[:2], s[2:4], s[4:8]\n",
    "        rest = s[8:]   # any extra trailing digits\n",
    "        s = f\"{dd}/{mm}/{yyyy}{rest}\"\n",
    "\n",
    "    pred_texts.append(s)\n",
    "\n",
    "print(pred_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ffad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
